---
output: md_document
author: "Imke Mayer"
date: 2018-10-24
title: Bibliography by topics
weight: 2
url: "/bibliography/biblio_topics/"
---



<p>Inspired by <a href="https://cran.r-project.org/web/views/MissingData.html" target="_blank">CRAN Task View on Missing Data</a> and a <a href="http://journal-sfds.fr/article/view/681" target="_blank">review</a> of Imbert &amp; Villa-Vialaneix on handling missing values (2018, written in French) we organized our selection of relevant references on missing values by different topics.</p>
<p><em>The full list of references can be found <a href="../biblio_complete/">here</a>.</em></p>
<div id="notations" class="section level4">
<h4>Notations</h4>
<p>In order to provide a more formal introduction for the problem of missing values and the existing methods to handle them (e.g. diagnose/describe the missingness or perform statistical analysis on the incomplete data), we introduce some farely standard definitions and notations used in the remainder of this article.</p>
<ul>
<li>Let <span class="math inline">\(X=(X_1,\dots, X_p)\)</span> be a vector of <span class="math inline">\(p\)</span> random variables which can be continuous or categorical.</li>
<li>We note <span class="math inline">\(x_{ij}\)</span> the observation of variable <span class="math inline">\(X_j\)</span> for an individual <span class="math inline">\(i\in\{1,\dots,n\}\)</span> and <span class="math inline">\(\mathbf{x}_i=(x_{i1},\dots,x_{ip})\)</span> the vector of observations of all <span class="math inline">\(p\)</span> variables <span class="math inline">\(X\)</span> for the individual <span class="math inline">\(i\)</span>.</li>
<li>The observations of the <span class="math inline">\(n\)</span> individuals are stacked by rows in a matrix <span class="math inline">\(\mathbf{X}\in\mathbb{R}^{n\times p}\)</span>.</li>
<li>The indicator matrix of missing values <span class="math inline">\(\mathbf{R}\)</span> is defined such that its values <span class="math inline">\((r_{ij})_{\substack{i=1,\dots,n\\j=1,\dots,p}}\)</span> are given by: <span class="math inline">\(r_{ij} = \left\{\begin{array}{ll}1 &amp; \text{ if } x_{ij} \text{ is observed}\\0 &amp; \text{ otherwise}\end{array}\right. = \mathbb{1}_{x_{ij}\, is\, observed}\)</span>. The associated random variable is denoted by <span class="math inline">\(R\)</span>.</li>
<li>The observed and missing parts of <span class="math inline">\(X\)</span> are denoted respectively by <span class="math inline">\(X_{obs}\)</span> and <span class="math inline">\(X_{mis}\)</span>.</li>
</ul>
</div>
<div id="general-references-and-reviews" class="section level3">
<h3>General references and reviews</h3>
<p>These general references and reviews are helpful to get started with the large field of missing values as they provide an introduction to the main concepts and methods or give an overview of the diversity of topics in statistical analysis related to missing values. They discuss different mechanisms that generated the missing values, necessary conditions for working consistently on the observed values alone and ways to impute, i.e. complete, the missing values to end up with complete datasets allowing the use of standard statistical analysis methods.</p>
<!-- Books and book chapters -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#gen_books">
Books and book chapters (9)
</button>
<div id="gen_books" class="collapse">
<ul>
<li><pref><cite>Allison, P. <em><font color="#428bca">Missing Data</font></em>. Quantitative Applications in the Social Sciences. Thousand Oaks, CA, USA: Sage Publications, 2001. ISBN: 9780761916727.</cite></pref>
<div>
<a href="https://doi.org/10.1136/bmj.38977.682025.2C" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Buuren, S. van. <em><font color="#428bca">Flexible Imputation of Missing Data</font></em>. Boca Raton, FL: Chapman and Hall/CRC, 2018.</cite></pref>
<div>
<a href="https://stefvanbuuren.name/fimd/" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Carpenter, J. and M. Kenward. <em><font color="#428bca">Multiple Imputation and its Application</font></em>. Chichester, West Sussex, UK: Wiley, 2013. ISBN: 9780470740521.</cite></pref>
<div>
<a href="https://doi.org/10.1002/9781119942283" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Enders, C. <em><font color="#428bca">Applied Missing Data Analysis</font></em>. Guilford Press, 2010, p. 401. ISBN: 9781606236390.</cite></pref></li>
<li><pref><cite>Kim, J. and J. Shao. <em><font color="#428bca">Statistical Methods for Handling Incomplete Data</font></em>. Boca Raton, FL, USA: Chapman and Hall/CRC, 2013. ISBN: 9781482205077.</cite></pref></li>
<li><pref><cite>Little, R. and D. Rubin. <em><font color="#428bca">Statistical Analysis with Missing Data</font></em>. Wiley, 2002, p. 408. ISBN: 0471183865.</cite></pref>
<div>
<a href="https://doi.org/10.2307/1533221" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Molenberghs, G., G. Fitzmaurice, M. G. Kenward, et al. <em><font color="#428bca">Handbook of Missing Data Methodology</font></em>. Chapman &amp; Hall/CRC Handbooks of Modern Statistical Methods. New York, NY, USA: Chapman and Hall/CRC, 2014. ISBN: 9781439854624.</cite></pref></li>
<li><pref><cite>Molenberghs, G. and M. Kenward. <em><font color="#428bca">Missing Data in Clinical Studies</font></em>. Chichester, West Sussex, UK: Wiley, 2007. ISBN: 9780470849811.</cite></pref>
<div>
<a href="https://doi.org/10.1002/9780470510445" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Schafer, J. <em><font color="#428bca">Analysis of Incomplete Multivariate Data</font></em>. CRC Monographs on Statistics &amp; Applied Probability. Boca Raton, FL, USA: Chapman and Hall/CRC, 1997. ISBN: 0412040611.</cite></pref></li>
</ul>
</div>
</div>
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#gen_journals">
Journal articles (4)
</button>
<div id="gen_journals" class="collapse">
<ul>
<li><pref><cite>Graham, J. <font color="#428bca">Missing data analysis: making it work in the real world</font>. In: <em>Annual Review of Psychology</em> 60 (2009), pp. 549-576.</cite></pref>
<div>
<a href="https://doi.org/10.1146/annurev.psych.58.110405.085530" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Kaiser, J. <font color="#428bca">Dealing with missing values in data</font>. In: <em>Journal of Systems Integration</em> 5.1 (2014), pp. 42-51.</cite></pref>
<div>
<a href="https://doi.org/10.20470/jsi.v5i1.178" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Pigott, T. <font color="#428bca">A review of methods for missing data</font>. In: <em>Educational Research and Evaluation</em> 7.4 (2001), pp. 353-383.</cite></pref>
<div>
<a href="https://doi.org/10.1076/edre.7.4.353.8937" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Schafer, J. and J. Graham. <font color="#428bca">Missing data: our view of the state of the art</font>. In: <em>Psychological Methods</em> 7.2 (2002), pp. 147-177.</cite></pref>
<div>
<a href="https://doi.org/10.1037/1082-989X.7.2.147" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<!-- Reports, theses, etc. -->
<p><br></p>
<p>If you are rather new to the subject and wish to start with less formal and more application-based introductions or if you look for general high-level advices on handling missing data we suggest the following publications:</p>
<!-- Books and book chapters -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#gen2_books">
Books and book chapters (1)
</button>
<div id="gen2_books" class="collapse">
<ul>
<li><pref><cite>National Research Council, U. <em><font color="#428bca">The Prevention and Treatment of Missing Data in Clinical Trials</font></em>. Washington (DC), USA: National Academies Press, 2010. ISBN: 9780309158145.</cite></pref>
<div>
<a href="https://doi.org/10.17226/12955" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#gen2_journals">
Journal articles (5)
</button>
<div id="gen2_journals" class="collapse">
<ul>
<li><pref><cite>Baraldi, A. and C. Enders. <font color="#428bca">An introduction to modern missing data analysis</font>. In: <em>Journal of School Psychology</em> 48.1 (2010), pp. 5-37.</cite></pref>
<div>
<a href="https://doi.org/10.1016/j.jsp.2009.10.001" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Dax, A. <font color="#428bca">Imputing Missing Entries of a Data Matrix: A review</font>. In: <em>Journal of Advanced Computing</em> 3.3 (2014), pp. 98-222.</cite></pref>
<div>
<a href="https://doi.org/10.7726/jac.2014.1007" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Dong, Y. and C. J. Peng. <font color="#428bca">Principled missing data methods for researchers</font>. In: <em>SpringerPlus</em> 2 (2013), p. 222.</cite></pref>
<div>
<a href="https://doi.org/10.1186/2193-1801-2-222" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Horton, N. and K. Kleinman. <font color="#428bca">Much Ado About Nothing - A Comparison of Missing Data Methods and Software to Fit Incomplete Data Regression Models</font>. In: <em>The American Statistician</em> 61.1 (2017), pp. 79-90.</cite></pref>
<div>
<a href="https://doi.org/10.1198/000313007X172556" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Peugh, J. L. and C. K. Enders. <font color="#428bca">Missing data in educational research: a review of reporting practices and suggestions for improvement</font>. In: <em>Review of Educational Research</em> 74.4 (2004), pp. 525–556.</cite></pref>
<div>
<a href="https://doi.org/10.3102/00346543074004525" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a><a href="http://dx.doi.org/10.3102/00346543074004525" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<!-- Reports, theses, etc. -->
<p><br></p>
<p>Furthermore you can have a look at the following statistical journals which regularly contain recent results related to handling missing data:</p>
<ul>
<li><p><a href="https://rss.onlinelibrary.wiley.com/journal/17409713" target="_blank">Significance</a> (bimonthly magazine)</p></li>
<li><p><a href="http://www3.stat.sinica.edu.tw/statistica/" target="_blank">Statistica sinica</a> (quarterly journal; Volume 28, Number 4, October 2018 on <em>Data Missing Not at Random</em>)</p></li>
<li><p><a href="https://www.imstat.org/journals-and-publications/statistical-science/" target="_blank">Statistical Science</a> (quarterly journal; Volume 33, Number 2, May 2018 on <em>Missing Data</em>)</p></li>
<li><p><a href="https://www.tandfonline.com/action/journalInformation?show=aimsScope&amp;journalCode=utas20" target="_blank">The American Statistician</a> (quarterly journal)</p></li>
</ul>
<p><br></p>
</div>
<div id="weighting-methods" class="section level3">
<h3>Weighting methods</h3>
<p>The first intuitive and probably most applied solution in data analyses to deal with missing values is to delete the partial observations and to work excusively on the individuals with complete information. This has several drawbacks, among others it introduces an estimation bias in most cases (more precisely in cases where the missingness is not independent of the data). In order to reduce this bias one can reweight the complete observations to compensate for the deletion of incomplete individuals in the dataset. The weights are defined by inverse probabilities, for instance the inverse of the probability for each individual of being fully observed. This method is known as <em>inverse probability weighting</em> and is described in detail in the publications below. We split the references in two parts: handling missing values in survey data and performing causal inference in the presence of missing values, both requiring the use of weighting methods.</p>
<div id="for-survey-data-analysis" class="section level4">
<h4>For survey data analysis</h4>
<p>Such weighting methods are widely used on survey data in order to correct for unbalanced sampling fractions by balancing the empirical distributions of the observed covariates to recover the structure of the target population.</p>
<!-- Books and book chapters -->
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#weight_journals">
Journal articles (5)
</button>
<div id="weight_journals" class="collapse">
<ul>
<li><pref><cite>Buck, S. <font color="#428bca">A method of estimation of missing values in multivariate data suitable for use with an electronic computer</font>. In: <em>Journal of the Royal Statistical Society, Series B</em> 22 (1960), pp. 302-306.</cite></pref>
<div>
<a href="https://doi.org/10.1177/004912417700600206" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Gelman, A., G. King and C. Liu. <font color="#428bca">Not asked and not answered: Multiple imputation for multiple surveys</font>. In: <em>Journal of the American Statistical Association</em> 93.443 (1998), pp. 846–857.</cite></pref>
<div>
<a href="https://doi.org/10.1080/01621459.1998.10473737" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Kalton, G. and D. Kasprzyk. <font color="#428bca">The treatment of missing survey data</font>. In: <em>Survey Methodology</em> 12.1 (1986), pp. 1-16.</cite></pref>
<div>
<a href="http://www.statcan.gc.ca/pub/12-001-x/1986001/article/14404-eng.pdf" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Rubin, D. <font color="#428bca">Formalizing subjective notions about the effect of nonrespondents in sample surveys</font>. In: <em>Journal of the American Statistical Association</em> 72.359 (1977), pp. 538-543.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2286214" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Seaman, S. and I. White. <font color="#428bca">Review of inverse probability weighting for dealing with missing data</font>. In: <em>Statistical Methods in Medical Research</em> 22.3 (2011), pp. 278-295.</cite></pref>
<div>
<a href="https://doi.org/10.1177/0962280210395740" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<!-- Reports, theses, etc. -->
<p></br></p>
</div>
<div id="for-causal-inference" class="section level4">
<h4>For causal inference</h4>
<p>Inverse probability weighting is also considered in causal inference: A bias is induced by the presence of confounders, i.e. variables which interact with both covariates and outcome. Hence, if the goal is to estimate causal relationships between covariates and outcome it is necessary to account for the potential effect of confounders – a selection bias – on the result of causal inference.</p>
<!-- Books and book chapters -->
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#weight2_journals">
Journal articles (3)
</button>
<div id="weight2_journals" class="collapse">
<ul>
<li><pref><cite>Bang, H. and J. Robins. <font color="#428bca">Doubly robust estimation in missing data and causal inference models</font>. In: <em>Biometrics</em> 61.4 (2005), pp. 962-973.</cite></pref>
<div>
<a href="https://doi.org/10.1111/j.1541-0420.2005.00377.x" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Hogan, J. and T. Lancaster. <font color="#428bca">Instrumental variables and inverse probability weighting for causal inference from longitudinal observational studies</font>. In: <em>Statistical Methods in Medical Research</em> 13.1 (2004), pp. 17-48.</cite></pref>
<div>
<a href="https://doi.org/10.1191/0962280204sm351ra" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Wal, W. M. van der and R. B. Geskus. <font color="#428bca">ipw: an R package for inverse probability weighting</font>. In: <em>Journal of Statistical Software</em> 43.13 (2011).</cite></pref>
<div>
<a href="https://doi.org/10.18637/jss.v043.i13" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#weight2_conf">
Conference papers (1)
</button>
<div id="weight2_conf" class="collapse">
<ul>
<li><pref><cite>Kallus, N., X. Mao and M. Udell. <font color="#428bca">Causal Inference with Noisy and Missing Covariates via Matrix Factorization</font>. In: <em>Advances in Neural Information Processing Systems</em>. Ed. by -. 2018. eprint: 1806.00811.</cite></pref>
<div>
<a href="https://arxiv.org/abs/1806.00811" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
</ul>
</div>
</div>
<!-- Reports, theses, etc. -->
<p><br></p>
</div>
</div>
<div id="hot-deck-and-knn-approaches" class="section level3">
<h3>Hot-deck and kNN approaches</h3>
<p>Let <span class="math inline">\(x_i\)</span> be an observation with missing values, e.g. each entry of <span class="math inline">\(x_i\)</span> could be the temperature at a certain day for one given place and unfortunately for some days the temperature was not measured. An intuitive idea to replace this missing information could be: take other observations <span class="math inline">\(\{x_j\}_j\)</span> which are similar to <span class="math inline">\(x_i\)</span> at the observed values and use this information to <em>fill in</em> the gaps. This idea of taking observed values from <em>neighbours</em> or <em>donors</em> based on some similarity measure is implemented in the so-called <em>hot-deck</em> and <em>k-nearest-neighbors</em> (kNN) approaches.</p>
<!-- Books and book chapters -->
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#hot_journals">
Journal articles (7)
</button>
<div id="hot_journals" class="collapse">
<ul>
<li><pref><cite>Andridge, R. and R. Little. <font color="#428bca">A review of hot deck imputation for survey non-response</font>. In: <em>International Statistical Review</em> 78.1 (2010), pp. 40-64.</cite></pref>
<div>
<a href="https://doi.org/10.1111/j.1751-5823.2010.00103.x" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Huisman, M. <font color="#428bca">Imputation of missing item responses: some simple techniques</font>. In: <em>Quality &amp; Quantity</em> 34.4 (2000), pp. 331-351.</cite></pref>
<div>
<a href="https://doi.org/10.1023/A:1004782230065" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Imbert, A., A. Valsesia, C. Le Gall, et al. <font color="#428bca">Multiple hot-deck imputation for network inference from RNA sequencing data</font>. In: <em>Bioinformatics</em> 34.10 (2018), pp. 1726-1732.</cite></pref>
<div>
<a href="https://doi.org/10.1093/bioinformatics/btx819" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Joenssen, D. and U. Bankhofer. <font color="#428bca">Donor limited hot deck imputation: effect on parameter estimation</font>. In: <em>Journal of Theoretical and Applied Computer Science</em> 6.3 (2012), pp. 58-70.</cite></pref>
<div>
<a href="http://www.jtacs.org/archive/2012/3/6" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Rao, J. and J. Shao. <font color="#428bca">Jackknife variance estimation with survey data under hot deck imputation</font>. In: <em>Biometrika</em> 79.4 (1992), pp. 811-822.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2337236" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Reilly, M. and M. Pepe. <font color="#428bca">The relationship between hot-deck multiple imputation and weighted likelihood</font>. In: <em>Statistics in Medecine</em> 16.1-3 (1997), pp. 5-19.</cite></pref>
<div>
<a href="https://doi.org/10.1002/(SICI)1097-0258(19970115)16:1%3C5::AID-SIM469%3E3.0.CO;2-8" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Voillet, V., P. Besse, L. Liaubet, et al. <font color="#428bca">Handling missing rows in multi-omics data integration: multiple imputation in multiple factor analysis framework</font>. In: <em>BMC Bioinformatics</em> 17.402 (2016). Forthcoming.</cite></pref>
<div>
<a href="https://doi.org/10.1186/s12859-016-1273-5" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<!-- Reports, theses, etc. -->
<p><br></p>
</div>
<div id="likelihood-based-approaches" class="section level3">
<h3>Likelihood-based approaches</h3>
<p>Likelihood-based approaches in the presence of missing values are designed for statistical inference from incomplete data. More precisely, if the missingness mechanism is ignorable (in a certain sense that is explained in the <em>Missing values mechanisms</em> section) then one can attempt to infer the model parameters by maximizing the likelihood on the observed values. When the mechanism cannot be ignored, then a specific model for it needs to be assumed. The main algorithm available for performing maximum likelihood estimation (ML) with missing values, is the <em>Expectation Maximization</em> (EM) algorithm. This algorithm requires the knowledge of the joint distribution of <span class="math inline">\(X = (X_{obs}, X_{mis})\)</span> and its implementation is not straightforward since it involves integrals which cannot always be computed easily. Once the model parameters are estimated, one can impute the missing values using this estimated information on the data model. TBC.</p>
<!-- Books and book chapters -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#ml_books">
Books and book chapters (1)
</button>
<div id="ml_books" class="collapse">
<ul>
<li><pref><cite>McLachlan, G. and T. Krishnan. <em><font color="#428bca">The EM Algorithm and Extensions</font></em>. Wiley series in probability and statistics. Hoboken, NJ, USA: Wiley, 2008. ISBN: 9780471201700.</cite></pref></li>
</ul>
</div>
</div>
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#ml_journals">
Journal articles (14)
</button>
<div id="ml_journals" class="collapse">
<ul>
<li><pref><cite>Collins, L. M., J. L. Schafer and K. Chi-Ming. <font color="#428bca">A comparison of inclusive and restrictive strategies in modern missing data procedures</font>. In: <em>Psychological Methods</em> 6.4 (2007), pp. 330-351.</cite></pref>
<div>
<a href="https://doi.org/10.1037/1082-989X.6.4.330" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Enders, C. <font color="#428bca">A primer on maximum likelihood algorithms available for use with missing data</font>. In: <em>Structural Equation Modeling</em> 8.1 (2001), pp. 128-141.</cite></pref>
<div>
<a href="https://doi.org/10.1207/S15328007SEM0801_7" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Finkbeiner, C. <font color="#428bca">Estimation for the multiple factor model when data are missing</font>. In: <em>Psychometrika</em> 44.4 (1979), pp. 409-420.</cite></pref>
<div>
<a href="https://doi.org/10.1007/BF02296204" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Ibrahim, J., S. Lipsitz and M. Chen. <font color="#428bca">Missing Covariates in Generalized Linear Models When the Missing Data Mechanism is Non-Ignorable</font>. In: <em>Journal of the Royal Statistical Society</em>. Series B (Statistical Methodology) 61.1 (1999), pp. 173-190.</cite></pref>
<div>
<a href="https://doi.org/10.1111/1467-9868.00170" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a><a href="http://www.jstor.org/stable/2680744" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Ibrahim, J., M. Chen and S. Lipsitz. <font color="#428bca">Missing responses in generalised linear mixed models when the missing data mechanism is nonignorable</font>. In: <em>Biometrika</em> 88.2 (2001), pp. 551-564.</cite></pref>
<div>
<a href="https://doi.org/10.1093/biomet/88.2.551" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Little, R. J. <font color="#428bca">Regression with missing X’s: a review</font>. In: <em>Journal of the American Statistical Association</em> 87.420 (1992), pp. 1227-1237.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2290664" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Meng, S. and D. Rubin. <font color="#428bca">Maximum likelihood estimation via the ECM algorithm: a general framework</font>. In: <em>Biometrika</em> 80.2 (1993), pp. 267-278.</cite></pref>
<div>
<a href="https://doi.org/10.1093/biomet/80.2.267" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Meng, X. and D. Rubin. <font color="#428bca">Using EM to obtain asymptotic variance-covariance matrices: the SEM algorithm</font>. In: <em>Journal of the American Statistical Association</em> 86.416 (1991), pp. 899-909.</cite></pref>
<div>
<a href="https://doi.org/10.1080/01621459.1991.10475130" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Rosseel, Y. <font color="#428bca">lavaan: an R package for structural equation modeling</font>. In: <em>Journal of Statistical Software</em> 48.2 (2012).</cite></pref>
<div>
<a href="https://doi.org/10.18637/jss.v048.i02" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Rubin, D. <font color="#428bca">Inference and missing data</font>. In: <em>Biometrika</em> 63.3 (1976), pp. 581-592.</cite></pref>
<div>
<a href="https://doi.org/10.1093/biomet/63.3.581" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Stubbendick, A. and J. Ibrahim. <font color="#428bca">Maximum Likelihood Methods for Nonignorable Missing Responses and Covariates in Random Effects Models</font>. In: <em>Biometrics</em> 59.4 (2003), pp. 1140–1150.</cite></pref>
<div>
<a href="https://doi.org/10.1111/j.0006-341X.2003.00131.x" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Stubbendick, A. and J. Ibrahim. <font color="#428bca">Likelihood-based inference with nonignorable missing responses and covariates in models for discrete longitudinal data</font>. In: <em>Statistica Sinica</em> 16.4 (2006), pp. 1143–1167.</cite></pref>
<div>
<a href="https://www.jstor.org/stable/24307781" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Tchetgen Tchetgen, E., L. Wang and B. Sun. <font color="#428bca">Discrete choice models for nonmonotone nonignorable missing data: identification and inference</font>. In: <em>Statistica Sinica</em> 28.4 (2018), pp. 2069–2088.</cite></pref>
<div>
<a href="https://doi.org/10.5705/ss.202016.0325" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Zhou, Y., R. Little and J. Kalbfleisch. <font color="#428bca">Block-conditional missing at random models for missing data</font>. In: <em>Statistical Science</em> 25.4 (2010), pp. 517–532.</cite></pref>
<div>
<a href="https://doi.org/10.1214/10-STS344" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<!-- Reports, theses, etc. -->
<p><br></p>
</div>
<div id="single-imputation" class="section level3">
<h3>Single imputation</h3>
<p>In the previously mentioned EM algorithm there is in fact an implicit step called <em>imputation</em>: imputing a missing value means replacing it with a <em>plausible</em> one. The definition of <em>plausibility</em> is not stated explicitly but can be deduced from the used method to <em>fill in</em> the gaps, for instance one could choose to replace all missing values of a certain variable <span class="math inline">\(X_j\)</span> by the average observed value <span class="math inline">\(\frac{1}{n_{obs,j}}\sum_{i} x_{ij}\mathbb{1}_{\{x_{ij} \, is\, observed\}}\)</span>, where <span class="math inline">\(n_{obs,j} = \sum_{i} \mathbb{1}_{\{x_{ij} \, is\, observed\}}\)</span>. The interest of imputation is manifold: (1) it allows to use all information in the sample (instead of deleting incomplete observations which leads to a decreasing power in the statistical analysis), (2) if there is sufficient data, i.e. sufficient observations, then the imputation can be very accurate and this assures good quality of future statistical analyses and (3) the imputed dataset is a complete dataset and one can apply standard statistical inference methods. The latter however has to be treated with caution since it implies that in the statistical analysis one does not make any distinction between observed values and imputed values anymore. We will come back to this issue in the next section on <em>multiple imputation</em>.</p>
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#imp_journals">
Journal articles (24)
</button>
<div id="imp_journals" class="collapse">
<ul>
<li><pref><cite>Audigier, V., F. Husson and J. Josse. <font color="#428bca">A principal component method to impute missing values for mixed data</font>. In: <em>Advances in Data Analysis and Classification</em> 10.1 (2016), pp. 5-26.</cite></pref>
<div>
<a href="https://doi.org/10.1007/s11634-014-0195-1" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Cranmer, S. and J. Gill. <font color="#428bca">We have to be discrete about this: a non-parametric imputation technique for missing categorical data</font>. In: <em>British Journal of Political Science</em> 43 (2012), pp. 425-449.</cite></pref>
<div>
<a href="https://doi.org/10.1017/S0007123412000312" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Crookston, N. and A. Finley. <font color="#428bca">yaImpute: an R package for kNN imputation</font>. In: <em>Journal of Statistical Software</em> 23 (2008), p. 10.</cite></pref>
<div>
<a href="https://doi.org/10.18637/jss.v023.i10" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Dax, A. <font color="#428bca">Imputing Missing Entries of a Data Matrix: A review</font>. In: <em>Journal of Advanced Computing</em> 3.3 (2014), pp. 98-222.</cite></pref>
<div>
<a href="https://doi.org/10.7726/jac.2014.1007" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Ding, Y. and J. Simonoff. <font color="#428bca">An investigation of missing data methods for classification trees applied to binary response data</font>. In: <em>Journal of Machine Learning Research</em> 11.1 (2010), pp. 131-170.</cite></pref>
<div>
<a href="http://www.jmlr.org/papers/v11/ding10a.html" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Fellegi, I. and D. Holt. <font color="#428bca">A systematic approach to automatic edit and imputation</font>. In: <em>Journal of the American Statistical Association</em> 71.353 (1976), pp. 17-35.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2285726" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Ferrari, P. A., P. Annoni, A. Barbiero, et al. <font color="#428bca">An imputation method for categorical variables with application to nonlinear principal component analysis</font>. In: <em>Computational Statistics &amp; Data Analysis</em> 55.7 (2011), pp. 2410-2420.</cite></pref>
<div>
<a href="https://doi.org/10.1016/j.csda.2011.02.007" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Finkbeiner, C. <font color="#428bca">Estimation for the multiple factor model when data are missing</font>. In: <em>Psychometrika</em> 44.4 (1979), pp. 409-420.</cite></pref>
<div>
<a href="https://doi.org/10.1007/BF02296204" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Huisman, M. <font color="#428bca">Imputation of missing item responses: some simple techniques</font>. In: <em>Quality &amp; Quantity</em> 34.4 (2000), pp. 331-351.</cite></pref>
<div>
<a href="https://doi.org/10.1023/A:1004782230065" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Husson, F. and J. Josse. <font color="#428bca">Handling missing values in multiple factor analysis</font>. In: <em>Food Quality and Preference</em> 30 (2013), pp. 77-85.</cite></pref>
<div>
<a href="https://doi.org/10.1016/j.foodqual.2013.04.013" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Ilin, A. and T. Raiko. <font color="#428bca">Practical approaches to Principal Component Analysis in the presence of missing values</font>. In: <em>Journal of Machine Learning Research</em> 11 (2010), pp. 1957-2000.</cite></pref>
<div>
<a href="http://jmlr.csail.mit.edu/papers/v11/ilin10a.html" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Joenssen, D. and U. Bankhofer. <font color="#428bca">Donor limited hot deck imputation: effect on parameter estimation</font>. In: <em>Journal of Theoretical and Applied Computer Science</em> 6.3 (2012), pp. 58-70.</cite></pref>
<div>
<a href="http://www.jtacs.org/archive/2012/3/6" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Josse, J., M. Chavent, B. Liquet, et al. <font color="#428bca">Handling missing values with regularized iterative multiple correspondance analysis</font>. In: <em>Journal of Classification</em> 29.1 (2012), pp. 91-116.</cite></pref>
<div>
<a href="https://doi.org/10.1007/s00357-012-9097-0" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Josse, J., F. Husson and J. Pagès. <font color="#428bca">Gestion des données manquantes en Analyse en Composantes Principales</font>. In: <em>Journal de la Société Française de Statistique</em> 150.2 (2009), pp. 28-51.</cite></pref>
<div>
<a href="http://journal-sfds.fr/ojs/index.php/J-SFdS/article/view/33/27" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Kalton, G. and D. Kasprzyk. <font color="#428bca">The treatment of missing survey data</font>. In: <em>Survey Methodology</em> 12.1 (1986), pp. 1-16.</cite></pref>
<div>
<a href="http://www.statcan.gc.ca/pub/12-001-x/1986001/article/14404-eng.pdf" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Kohn, R. and C. F. Ansley. <font color="#428bca">Estimation, prediction, and interpolation for ARIMA models with missing data</font>. In: <em>Journal of the American Statistical Association</em> 81.395 (1986), pp. 751-761.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2289007" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Kowarik, A. and M. Templ. <font color="#428bca">Imputation with the R Package VIM</font>. In: <em>Journal of Statistical Software</em> 74.7 (2016), pp. 1-16.</cite></pref>
<div>
<a href="https://doi.org/10.18637/jss.v074.i07" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Moritz, S. and T. Bartz-Beielstein. <font color="#428bca">imputeTS: time series missing value imputation in R</font>. In: <em>The R Journal</em> 9.1 (2017), pp. 207-218.</cite></pref>
<div>
<a href="https://journal.r-project.org/archive/2017/RJ-2017-009/index.html" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Stacklies, W., H. Redestig, M. Scholz, et al. <font color="#428bca">pcaMethods – a bioconductor package providing PCA methods for incomplete data</font>. In: <em>Bioconductor</em> 23.9 (2007), pp. 1164-1167.</cite></pref>
<div>
<a href="https://doi.org/10.1093/bioinformatics/btm069" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Troyanskaya, O., M. Cantor, G. Sherlock, et al. <font color="#428bca">Missing value estimation methods for DNA microarrays</font>. In: <em>Bioinformatics</em> 17.6 (2001), pp. 520-525.</cite></pref>
<div>
<a href="https://doi.org/10.1093/bioinformatics/17.6.520" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Unnebrink, K. and J. Windeler. <font color="#428bca">Intention-to-treat: methods for dealing with missing values in clinical trials of progressively deteriorating diseases</font>. In: <em>Statistics in Medecine</em> 20.24 (2001), pp. 3931-3946.</cite></pref>
<div>
<a href="https://doi.org/10.1002/sim.1149" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Verbanck, M., J. Josse and F. Husson. <font color="#428bca">Regularised PCA to denoise and visualise data</font>. In: <em>Statistics and Computing</em> 25.2 (2015), pp. 471-486.</cite></pref>
<div>
<a href="https://doi.org/10.1007/s11222-013-9444-y" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Zhang, H., P. Xie and E. Xing. <font color="#428bca">Missing Value Imputation Based on Deep Generative Models</font>. In: <em>Computing Research Repository</em> abs/1808.01684 (2018).</cite></pref>
<div>
<a href="https://arxiv.org/abs/1808.01684" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Zhang, S. <font color="#428bca">Nearest neighbor selection for iterative kNN imputation</font>. In: <em>Journal of Systems and Software</em> 85.11 (2012), pp. 2541-2552.</cite></pref>
<div>
<a href="https://doi.org/10.1016/j.jss.2012.05.073" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#imp_conf">
Conference papers (1)
</button>
<div id="imp_conf" class="collapse">
<ul>
<li><pref><cite>Tran, L., X. Liu, J. Zhou, et al. <font color="#428bca">Missing Modalities Imputation via Cascaded Residual Autoencoder</font>. In: <em>2017 IEEE Conference on Computer Vision and PAttern Recognition (CVPR)</em>. (Jul. 21, 2017-Jul. 26, 2017). Ed. by -. IEEE, 2017, pp. 4971-4980.</cite></pref>
<div>
<a href="https://doi.org/10.1109/CVPR.2017.528" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#imp_misc">
Reports, theses, etc. (1)
</button>
<div id="imp_misc" class="collapse">
<ul>
<li><pref><cite>Moritz, S., A. Sardá, T. Bartz-Beielstein, et al. <font color="#428bca">Comparison of different methods for univariate time series imputation in R</font>. Prepint arXiv 1510.03924. 2015.</cite></pref>
<div>
<a href="https://arxiv.org/abs/1510.03924" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
</ul>
</div>
</div>
<p><br></p>
</div>
<div id="multiple-imputation" class="section level3">
<h3>Multiple imputation</h3>
<p>A major drawback of single imputation, i.e. where every missing value is replaced by a single most plausible value, consists in the underestimation of the overall variance of the data and inferred parameters. Indeed, by replacing every missing value by a given <em>plausible</em> one and by applying generic statistical methods on the completed dataset, one makes no difference between initially observed and unobserved data anymore. Therefore the variability due to the uncertainty of the missing values is not reflected in future statistical analyses which treat the dataset as if it had been fully observed from the beginning. A nice and conceptually simple workaround for this problem is <em>multiple imputation</em>: instead of generating a single complete dataset by a given imputation method one imputes every missing value by several possible values. Statistical analysis is then applied on each of the imputed datasets and the resulting estimations are aggregated and used to estimate the sample variance and the variance due to the uncertainty in the missing values.</p>
<!-- Books and book chapters -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#mi_books">
Books and book chapters (2)
</button>
<div id="mi_books" class="collapse">
<ul>
<li><pref><cite>Carpenter, J. and M. Kenward. <em><font color="#428bca">Multiple Imputation and its Application</font></em>. Chichester, West Sussex, UK: Wiley, 2013. ISBN: 9780470740521.</cite></pref>
<div>
<a href="https://doi.org/10.1002/9781119942283" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Rubin, D. <em><font color="#428bca">Multlipe Imputation for Nonresponse in Surveys</font></em>. Hoboken, NJ, USA: Wiley, 1987. ISBN: 9780471655740.</cite></pref></li>
</ul>
</div>
</div>
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#mi_journals">
Journal articles (25)
</button>
<div id="mi_journals" class="collapse">
<ul>
<li><pref><cite>Abayomi, K., A. Gelman and M. Levy. <font color="#428bca">Diagnostics for multivariate imputations</font>. In: <em>Journal of the Royal Statistical Society, Series C (Applied Statistics)</em> 57.3 (2008), pp. 273-291.</cite></pref>
<div>
<a href="https://doi.org/10.1111/j.1467-9876.2007.00613.x" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Audigier, V., F. Husson and J. Josse. <font color="#428bca">MIMCA: multiple imputation for categorical variables with multiple correspondence analysis</font>. In: <em>Statistics and Computing</em> 27.2 (2016), pp. 1-18. eprint: 1505.08116.</cite></pref>
<div>
<a href="https://doi.org/10.1007/s11222-016-9635-4" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Audigier, V., F. Husson and J. Josse. <font color="#428bca">Multiple imputation for continuous variables using a Bayesian principal component analysis</font>. In: <em>Journal of Statistical Computation and Simulation</em> 86.11 (2015), pp. 2140-2156.</cite></pref>
<div>
<a href="https://doi.org/10.1080/00949655.2015.1104683" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Buuren, S. van. <font color="#428bca">Multiple imputation of discrete and continuous data by fully conditional specification</font>. In: <em>Statistical Methods in Medical Research</em> 16 (2007), pp. 219-242.</cite></pref>
<div>
<a href="https://doi.org/10.1177/0962280206074463" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Buuren, S. van, J. Brand, C. Groothuis-Oudshoorn, et al. <font color="#428bca">Fully conditional specification in multivariate imputation</font>. In: <em>Journal of Statistical Computation and Simulation</em> 76.12 (2006), pp. 1049-1064.</cite></pref>
<div>
<a href="https://doi.org/10.1080/10629360600810434" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Buuren, S. van and K. Groothuis-Oudshoorn. <font color="#428bca">MICE: multivariate imputation by chained equations in R</font>. In: <em>Journal of Statistical Software</em> 45 (2011), p. 3. eprint: NIHMS150003.</cite></pref>
<div>
<a href="https://doi.org/10.18637/jss.v045.i03" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Collins, L. M., J. L. Schafer and K. Chi-Ming. <font color="#428bca">A comparison of inclusive and restrictive strategies in modern missing data procedures</font>. In: <em>Psychological Methods</em> 6.4 (2007), pp. 330-351.</cite></pref>
<div>
<a href="https://doi.org/10.1037/1082-989X.6.4.330" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Fay, R. <font color="#428bca">Alternative paradigms for the analysis of imputed survey data</font>. In: <em>Journal of the American Statistical Association</em> 91.434 (1996), pp. 490-498.</cite></pref>
<div>
<a href="https://doi.org/10.1080/01621459.1996.10476909" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Gelman, A., G. King and C. Liu. <font color="#428bca">Not asked and not answered: Multiple imputation for multiple surveys</font>. In: <em>Journal of the American Statistical Association</em> 93.443 (1998), pp. 846–857.</cite></pref>
<div>
<a href="https://doi.org/10.1080/01621459.1998.10473737" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Gelman, A., I. van Mechelen, G. Verbeke, et al. <font color="#428bca">Multiple Imputation for Model Checking: Completed-Data Plots with Missing and Latent Data</font>. In: <em>Biometrics</em> 61.1 (2005), pp. 74–85.</cite></pref>
<div>
<a href="https://doi.org/10.1111/j.0006-341X.2005.031010.x" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Graham, J. W., A. E. Olchowski and T. E. Gilreath. <font color="#428bca">How many imputations are really needed? Some practical clarifications of multiple imputation theory</font>. In: <em>Prevention Science</em> 8.3 (2007), pp. 206-213.</cite></pref>
<div>
<a href="https://doi.org/10.1007/s11121-007-0070-9" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Honaker, J., G. King and M. Blackwell. <font color="#428bca">Amelia II: a program for missing data</font>. In: <em>Journal of Statistical Software</em> 45.7 (2011). eprint: arXiv:1501.0228.</cite></pref>
<div>
<a href="https://doi.org/10.18637/jss.v045.i07" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Imbert, A., A. Valsesia, C. Le Gall, et al. <font color="#428bca">Multiple hot-deck imputation for network inference from RNA sequencing data</font>. In: <em>Bioinformatics</em> 34.10 (2018), pp. 1726-1732.</cite></pref>
<div>
<a href="https://doi.org/10.1093/bioinformatics/btx819" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Josse, J. and F. Husson. <font color="#428bca">missMDA: a package for handling missing values in multivariate data analysis</font>. In: <em>Journal of Statistical Software</em> 70.1 (2016), pp. 1-31.</cite></pref>
<div>
<a href="https://doi.org/10.18637/jss.v070.i01" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Josse, J. and F. Husson. <font color="#428bca">Handling missing values in exploratory multivariate data analysis methods</font>. In: <em>Journal de la Société Française de Statistique</em> 153.2 (2012), pp. 79-99.</cite></pref>
<div>
<a href="http://publications-sfds.fr/ojs/index.php/J-SFdS/article/view/122/112" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Josse, J., J. Pagès and F. Husson. <font color="#428bca">Multiple imputation in principal component analysis</font>. In: <em>Advances in Data Analysis and Classification</em> 5.3 (2011), pp. 231-246.</cite></pref>
<div>
<a href="https://doi.org/10.1007/s11634-011-0086-7" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Kropko, J., B. Goodrich, A. Gelman, et al. <font color="#428bca">Multiple Imputation for Continuous and Categorical Data: Comparing Joint Multivariate Normal and Conditional Approaches</font>. In: <em>Political Analysis</em> 22.4 (2014), pp. 497–519.</cite></pref>
<div>
<a href="https://doi.org/10.1093/pan/mpu007" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Murray, J. and J. Reiter. <font color="#428bca">Multiple Imputation of Missing Categorical and Continuous Values via Bayesian Mixture Models With Local Dependence</font>. In: <em>Journal of the American Statistical Association</em> 111.516 (2016), pp. 1466-1479.</cite></pref>
<div>
<a href="https://doi.org/10.1080/01621459.2016.1174132" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Robins, J. and N. Wang. <font color="#428bca">Inference for imputation estimators</font>. In: <em>Biometrika</em> 87.1 (2000), pp. 113-124.</cite></pref>
<div>
<a href="https://www.jstor.org/stable/2673565" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Rubin, D. <font color="#428bca">Multiple imputation after 18+ years</font>. In: <em>Journal of the American Statistical Association</em> 91.434 (2012), pp. 473-489.</cite></pref>
<div>
<a href="https://doi.org/10.1080/01621459.1996.10476908" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Schafer, J. <font color="#428bca">Multiple imputation: a primer</font>. In: <em>Statistical Methods in Medical Research</em> 8.1 (1999), pp. 3-15.</cite></pref>
<div>
<a href="https://doi.org/10.1191/096228099671525676" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Schafer, J. and M. Olsen. <font color="#428bca">Multiple Imputation for multivariate missing-data problems: a data analyst’s perspective</font>. In: <em>Multivariate Behavioral Research</em> 33.4 (1998), pp. 545-571.</cite></pref>
<div>
<a href="https://doi.org/10.1207/s15327906mbr3304_5" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Stuart, E., M. Azur, C. Frangakis, et al. <font color="#428bca">Multiple imputation with large data sets: a case study of the children’s mental health initiative</font>. In: <em>American Journal of Epidemiology</em> 169.9 (2009), pp. 1133-1139.</cite></pref>
<div>
<a href="https://doi.org/10.1093/aje/kwp026" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Su, Y., A. Gelman, J. Hill, et al. <font color="#428bca">Multiple imputation with diagnostics (mi) in R: opening windows into the black box</font>. In: <em>Journal of Statistical Software</em> 45 (2011), p. 2.</cite></pref>
<div>
<a href="https://doi.org/10.18637/jss.v045.i02" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Voillet, V., P. Besse, L. Liaubet, et al. <font color="#428bca">Handling missing rows in multi-omics data integration: multiple imputation in multiple factor analysis framework</font>. In: <em>BMC Bioinformatics</em> 17.402 (2016). Forthcoming.</cite></pref>
<div>
<a href="https://doi.org/10.1186/s12859-016-1273-5" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#mi_conf">
Conference papers (1)
</button>
<div id="mi_conf" class="collapse">
<ul>
<li><pref><cite>Gondara, L. and K. Wang. <font color="#428bca">MIDA: Multiple Imputation using Denoising Autoencoders</font>. In: <em>Proceedings of the 22nd Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2018)</em>. (Jun. 03, 2018-Jun. 06, 2018). Ed. by D. Phung, V. Tseng, G. Webb, B. Ho, M. Ganji and L. Rashidi. Lecture Notes in Computer Science. Springer International Publishing, 2018, pp. 260-272. ISBN: 3319930404.</cite></pref>
<div>
<a href="https://doi.org/10.1007/978-3-319-93040-4_21" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a><a href="https://arxiv.org/abs/1705.02737" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
</ul>
</div>
</div>
<!-- Reports, theses, etc. -->
<p><br></p>
</div>
<div id="machine-learning" class="section level3">
<h3>Machine Learning</h3>
<p>The field of machine learning being dependent on the availability of (good) training data, it is – in most real-world applications – necessarily facing the issue of missing data. Hence there has been an increasing attention to how to handle missing data, in the features and the output, in order to <em>learn</em> accurately from the data.</p>
<div id="trees-and-forests" class="section level4">
<h4>Trees and forests</h4>
<p>Decision trees are models based on recursive executions of elementary rules. This architecture grants them a variety of simple options to deal with missing values, without requiring prior imputation. A popular class of decision tree models is called <em>random trees</em> (or more generally <em>random forests</em>) and allows data analyses such as causal inference in the presence of missing values without the need of having to impute these missing values.</p>
<!-- Books and book chapters -->
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#tree_journals">
Journal articles (7)
</button>
<div id="tree_journals" class="collapse">
<ul>
<li><pref><cite>Ding, Y. and J. Simonoff. <font color="#428bca">An investigation of missing data methods for classification trees applied to binary response data</font>. In: <em>Journal of Machine Learning Research</em> 11.1 (2010), pp. 131-170.</cite></pref>
<div>
<a href="http://www.jmlr.org/papers/v11/ding10a.html" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Hothorn, T., K. Hornik and A. Zeileis. <font color="#428bca">Unbiased Recursive Partitioning: A Conditional Inference Framework</font>. In: <em>Journal of Computational and Graphical Statistics</em> 15.3 (2012), pp. 651-674.</cite></pref>
<div>
<a href="https://doi.org/10.1198/106186006X133933" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Kapelner, A. and J. Bleich. <font color="#428bca">Prediction with missing data via Bayesian additive regression trees</font>. In: <em>Canadian Journal of Statistics</em> 43.2 (2015), pp. 224-239.</cite></pref>
<div>
<a href="https://doi.org/10.1002/cjs.11248" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a><a href="https://arxiv.org/abs/1306.0618v3" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Stekhoven, D. and P. Bühlmann. <font color="#428bca">Missforest-non-parametric missing value imputation for mixed-type data</font>. In: <em>Bioinformatics</em> 28.1 (2012), pp. 112-118. eprint: 1105.0828.</cite></pref>
<div>
<a href="https://doi.org/10.1093/bioinformatics/btr597" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Strobl, C., A. Boulesteix and T. Augustin. <font color="#428bca">Unbiased split selection for classification trees based on the Gini Index</font>. In: <em>Computational Statistics &amp; Data Analysis</em> 52.1 (2007), pp. 483-501.</cite></pref>
<div>
<a href="https://doi.org/10.1016/j.csda.2006.12.030" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Tierney, N., F. Harden, M. Harden, et al. <font color="#428bca">Using decision trees to understand structure in missing data</font>. In: <em>BMJ Open</em> 5.6 (2015), p. e007450.</cite></pref>
<div>
<a href="https://doi.org/10.1136/bmjopen-2014-007450" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Twala, B., M. Jones and D. Hand. <font color="#428bca">Good methods for coping with missing data in decision trees</font>. In: <em>Pattern Recognition Letters</em> 29.7 (2008), pp. 950-956.</cite></pref>
<div>
<a href="https://doi.org/10.1016/j.patrec.2008.01.010" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#tree_conf">
Conference papers (1)
</button>
<div id="tree_conf" class="collapse">
<ul>
<li><pref><cite>Chen, T. and C. Guestrin. <font color="#428bca">XGBoost: A Scalable Tree Boosting System</font>. In: <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>. (Aug. 13, 2016-Aug. 17, 2016). Ed. by -. New York, NY, USA: ACM, 2016, pp. 785-794. ISBN: 0450342322.</cite></pref>
<div>
<a href="https://doi.org/10.1145/2939672.2939785" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Reports, theses, etc. -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#tree_misc">
Reports, theses, etc. (1)
</button>
<div id="tree_misc" class="collapse">
<ul>
<li><pref><cite>Rieger, A., T. Hothorn and C. Strobl. <em><font color="#428bca">Random forests with missing values in the covariates</font></em>. Tech. rep. 79. University of Munich, Department of Statistics, 2010.</cite></pref>
<div>
<a href="https://epub.ub.uni-muenchen.de/11481/1/techreport.pdf" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
</ul>
</div>
</div>
<p><br></p>
</div>
<div id="deep-learning" class="section level4">
<h4>Deep Learning</h4>
<p>The advance and success of <em>(deep) neural networks</em> in many research and application areas such as computer vision and natural language processing has also re-discovered the problem of handling missing values. Indeed the question of training neural networks on incomplete data has been considered even before the latest rise of deep learning and is considered to be essential due to the impact of missingness on the feasibility and quality of various learning problems.</p>
<!-- Books and book chapters -->
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#dl_journals">
Journal articles (4)
</button>
<div id="dl_journals" class="collapse">
<ul>
<li><pref><cite>Sharpe, P. and R. Solly. <font color="#428bca">Dealing with missing values in neural network-based diagnostic systems</font>. In: <em>Neural Computing &amp; Applications</em> 3.2 (1995), pp. 73-77.</cite></pref>
<div>
<a href="https://doi.org/10.1007/BF01421959" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Śmieja, M., Ł. Struski, J. Tabor, et al. <font color="#428bca">Processing of missing data by neural networks</font>. In: <em>Computing Research Repository</em> abs/1805.07405 (2018). eprint: 1805.07405.</cite></pref>
<div>
<a href="https://arxiv.org/abs/1805.07405" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Sovilj, D., E. Eirola, Y. Miche, et al. <font color="#428bca">Extreme learning machine for missing data using multiple imputations</font>. In: <em>Neurocomputing</em> 174.A (2016), pp. 220-231.</cite></pref>
<div>
<a href="https://doi.org/10.1016/j.neucom.2015.03.108" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Zhang, H., P. Xie and E. Xing. <font color="#428bca">Missing Value Imputation Based on Deep Generative Models</font>. In: <em>Computing Research Repository</em> abs/1808.01684 (2018).</cite></pref>
<div>
<a href="https://arxiv.org/abs/1808.01684" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#dl_conf">
Conference papers (6)
</button>
<div id="dl_conf" class="collapse">
<ul>
<li><pref><cite>Bengio, Y. and F. Gingras. <font color="#428bca">Recurrent neural networks for missing or asynchronous data</font>. In: <em>Proceedings of the 8th International Conference on Neural Information Processing Systems</em>. (Nov. 27, 1995-Dec. 02, 1995). Ed. by -. Cambridge, MA, USA: MIT Press, 1995, pp. 395-401.</cite></pref>
<div>
<a href="http://papers.nips.cc/paper/1126-recurrent-neural-networks-for-missing-or-asynchronous-data.pdf" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Gondara, L. and K. Wang. <font color="#428bca">MIDA: Multiple Imputation using Denoising Autoencoders</font>. In: <em>Proceedings of the 22nd Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2018)</em>. (Jun. 03, 2018-Jun. 06, 2018). Ed. by D. Phung, V. Tseng, G. Webb, B. Ho, M. Ganji and L. Rashidi. Lecture Notes in Computer Science. Springer International Publishing, 2018, pp. 260-272. ISBN: 3319930404.</cite></pref>
<div>
<a href="https://doi.org/10.1007/978-3-319-93040-4_21" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a><a href="https://arxiv.org/abs/1705.02737" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Goodfellow, I., M. Mirza, A. Courville, et al. <font color="#428bca">Multi-Prediction Deep Boltzmann Machines</font>. In: <em>Proceedings of the 26th International Conference on Neural Information Processing Systems</em>. (Dec. 05, 2013-Dec. 10, 2013). Ed. by C. Burges, L. Bottou, M. Welling, Z. Ghahramani and K. Weinberger. Advances in Neural Information Processing Systems 26. Curran Associates, Inc., 2013, pp. 548–556.</cite></pref>
<div>
<a href="http://papers.nips.cc/paper/5024-multi-prediction-deep-boltzmann-machines.pdf" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Nowicki, R., R. Scherer and L. Rutkowski. <font color="#428bca">Novel rough neural network for classification with missing data</font>. In: <em>21st International Conference on Methods and Models in Automation and Robotics (MMAR)</em>. (Sep. 29, 2016-Sep. 01, 2016). Ed. by -. IEEE, 2016, pp. 820–825.</cite></pref>
<div>
<a href="https://doi.org/10.1109/MMAR.2016.7575243" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Tran, L., X. Liu, J. Zhou, et al. <font color="#428bca">Missing Modalities Imputation via Cascaded Residual Autoencoder</font>. In: <em>2017 IEEE Conference on Computer Vision and PAttern Recognition (CVPR)</em>. (Jul. 21, 2017-Jul. 26, 2017). Ed. by -. IEEE, 2017, pp. 4971-4980.</cite></pref>
<div>
<a href="https://doi.org/10.1109/CVPR.2017.528" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Yoon, J., J. Jordon and M. van der Schaar. <font color="#428bca">GAIN: Missing Data Imputation using Generative Adversarial Nets</font>. In: <em>Proceedings of the 35th International Conference on Machine Learning</em>. (Jul. 10, 2018-Jul. 15, 2018). Ed. by J. Dy and A. Krause. Vol. 80. Proceedings of Machine Learning Research. Stockholmsmässan, Stockholm Sweden: PMLR, 2018, pp. 5689–5698.</cite></pref>
<div>
<a href="http://proceedings.mlr.press/v80/yoon18a.html" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
</ul>
</div>
</div>
<!-- Reports, theses, etc. -->
<p><br></p>
</div>
</div>
<div id="missing-values-mechanisms" class="section level3">
<h3>Missing values mechanisms</h3>
<p>As mentioned in the above sections, it is necessary to make assumptions on the <em>mechanism generating the missing values</em> or <em>response mechanism</em> in order to work with missing values. Broadly speaking, these assumptions indicate how much the missingness is related to the data itself. The assumptions made on the mechanism impact further steps in the data analysis (since some types of missingness can induce a bias on the analysis results) and are therefore crucial for valid analyses of data in the presence of missing values.</p>
<p>More formally, the response mechanism is defined as the conditional distribution of <span class="math inline">\(R\)</span> given <span class="math inline">\(X\)</span>, <span class="math inline">\(f(R|X)\)</span>. This distribution can depend on some parameter <span class="math inline">\(\psi\)</span> so that we have <span class="math inline">\(f(R|X;\psi)\)</span>. Little and Rubin (2002) defined three main categories of missing values depending on the form of the conditional distribution <span class="math inline">\(f\)</span>:</p>
<ul>
<li><p>Missing completely at random (MCAR): The missingness does not depend on the variables <span class="math inline">\(X\)</span>, i.e. <span class="math display">\[f(R|X;\psi) = f(R;\psi).\]</span></p></li>
<li><p>Missing at random (MAR): The missingness depends only on the observed variables <span class="math inline">\(X_{obs}\)</span>, i.e. <span class="math display">\[f(R|X;\psi) = f(R|X_{obs};\psi),\]</span> or alternatively <span class="math inline">\(f(R|X^1;\psi) = f(R|X^2;\psi)\)</span> for all <span class="math inline">\(X^1 = (X^1_{obs},X^1_{mis})\)</span> and <span class="math inline">\(X^2 = (X^2_{obs},X^2_{mis})\)</span> such that <span class="math inline">\(X^1_{obs} = X^2_{obs}\)</span>.</p></li>
<li><p>Missing not at random (MNAR): The missingness depends on the observed and missing values, i.e. <span class="math display">\[f(R|X;\psi) \neq f(R|X_{obs};\psi).\]</span> To understand this definition, take the example of alcohol consumption: alcoholics are less inclined to reveal their alcohol consumption, therefore the probability of missing information on the alcohol consumption depends on the amount of consumption itself. Another simple example is the information on income or wealth which is missing more often for individuals of very high or very low income.</p></li>
</ul>
<p>Note that MCAR is a special case of MAR and that these three categories are of increasing complexity with a large gap between the second and third. Indeed, most more or less generic methods which have been proposed in the last few decades are suited for data that is MAR. The case MNAR requires different techniques and further assumptions.</p>
<p>Note that Little and Rubin (2002) consider these three categories as <em>really missing values</em> as opposed to <em>not really missing values</em> where, in the case of categorical data, the missingness rather constitutes an additional category (for instance in a questionnaire with multiple choice answers, a participant can leave out a question because the category he wants to choose is not among the given choices).</p>
<!-- Books and book chapters -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#mnar_books">
Books and book chapters (1)
</button>
<div id="mnar_books" class="collapse">
<ul>
<li><pref><cite>Wainer, H., ed. <em><font color="#428bca">Drawing Inferences from Self-Selected Samples</font></em>. New York, NY, USA: Springer, 1986.</cite></pref></li>
</ul>
</div>
</div>
<!-- Journal articles -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#mnar_journals">
Journal articles (33)
</button>
<div id="mnar_journals" class="collapse">
<ul>
<li><pref><cite>Albert, P. and D. Follmann. <font color="#428bca">Modeling repeated count data subject to informative dropout</font>. In: <em>Biometrics</em> 56.3 (2000), pp. 667-677.</cite></pref>
<div>
<a href="https://doi.org/10.1111/j.0006-341X.2000.00667.x" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Diggle, P. and M. Kenward. <font color="#428bca">Informative drop-out in longitudinal data analysis</font>. In: <em>Journal of the Royal Statistical Society, Series C (Applied Statistics)</em> 43.1 (1994), pp. 49-93.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2986113" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Fang, F., J. Zhao and J. Shao. <font color="#428bca">Imputation-based adjusted score equations in generalized linear models with nonignorable missing covariate values</font>. In: <em>Statistica Sinica</em> 28.4 (2018), pp. 1677–1701.</cite></pref>
<div>
<a href="https://doi.org/10.5705/ss.202015.0437" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Follmann, D. and M. Wu. <font color="#428bca">An approximate generalized linear model with random effects for informative missing data</font>. In: <em>Biometrics</em> 51.1 (1995), pp. 151-168.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2533322" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Gad, A. and N. Darwish. <font color="#428bca">A shared parameter model for longitudinal data with missing values</font>. In: <em>American Journal of Applied Mathematics and Statistics</em> 1.2 (2013), pp. 30-35.</cite></pref>
<div>
<a href="http://pubs.sciepub.com/ajams/1/2/3" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Heckman, J. <font color="#428bca">The common structure of statistical models of truncation, sample selection and limited dependent variables and a simple estimator for such models</font>. In: <em>Annals of Economic and Social Measurement</em> 5.4 (1976), pp. 475-492.</cite></pref>
<div>
<a href="http://ideas.repec.org/h/nbr/nberch/10491.html" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Ibrahim, J., S. Lipsitz and M. Chen. <font color="#428bca">Missing Covariates in Generalized Linear Models When the Missing Data Mechanism is Non-Ignorable</font>. In: <em>Journal of the Royal Statistical Society</em>. Series B (Statistical Methodology) 61.1 (1999), pp. 173-190.</cite></pref>
<div>
<a href="https://doi.org/10.1111/1467-9868.00170" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a><a href="http://www.jstor.org/stable/2680744" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Ibrahim, J., M. Chen and S. Lipsitz. <font color="#428bca">Missing responses in generalised linear mixed models when the missing data mechanism is nonignorable</font>. In: <em>Biometrika</em> 88.2 (2001), pp. 551-564.</cite></pref>
<div>
<a href="https://doi.org/10.1093/biomet/88.2.551" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Jamshidian, M. and S. Jalal. <font color="#428bca">Tests of homoscedasticity, normality, and missing completely at random for incomplete multivariate data</font>. In: <em>Psychometrika</em> 75.4 (2010), pp. 649-674. eprint: NIHMS150003.</cite></pref>
<div>
<a href="https://doi.org/10.1007/s11336-010-9175-3" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Jamshidian, M., S. Jalal and C. Jansen. <font color="#428bca">MissMech: an R package for testing homoscedasticity, multivariate normality, and missing completely at random (MCAR)</font>. In: <em>Journal of Statistical Software</em> 56.6 (2014), pp. 1-31.</cite></pref>
<div>
<a href="https://doi.org/10.18637/jss.v056.i06" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Lee, K., R. Mitra and S. Biedermann. <font color="#428bca">Optimal design when outcome values are not missing at random</font>. In: <em>Statistica Sinica</em> 28.4 (2018), pp. 1821–1838.</cite></pref>
<div>
<a href="https://doi.org/10.5705/ss.202016.0526" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Little, R. <font color="#428bca">Modeling the drop-out mechanism in repeated-measures studies</font>. In: <em>Journal of the American Statistical Association</em> 90.431 (1995), pp. 1112-1121.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2291350" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Little, R. <font color="#428bca">Pattern-mixture models for multivariate incomplete data</font>. In: <em>Journal of the American Statistical Association</em> 88.421 (1993), pp. 125-134.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2290705" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Little, R. <font color="#428bca">A test of missing completely at random for multivariate data with missing values</font>. In: <em>Journal of the American Statistical Association</em> 83.404 (1988), pp. 1198-1202.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2290157" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Miao, W. and E. Tchetgen Tchetgen. <font color="#428bca">Identification and inference with nonignorable missing covariate data</font>. In: <em>Statistica Sinica</em> 28.4 (2018), pp. 2049–2067.</cite></pref>
<div>
<a href="https://doi.org/10.5705/ss.202016.0322" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Molenberghs, G., B. Michiels, M. Kenward, et al. <font color="#428bca">Monotone missing data and pattern-mixture models</font>. In: <em>Statistica Neerlandica</em> 52.2 (1998), pp. 153-161.</cite></pref>
<div>
<a href="https://doi.org/10.1111/1467-9574.00075" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Robins, J., A. Rotnitzky and L. Zhao. <font color="#428bca">Analysis of semiparametric regression models for repeated outcomes in the presence of missing data</font>. In: <em>Journal of the American Statistical Association</em> 90.429 (1995), pp. 106-121.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2291134" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Rotnitzky, A., J. Robins and D. Scharfstein. <font color="#428bca">Semiparametric regression for repeated outcomes with nonignorable nonresponse</font>. In: <em>Journal of the American Statistical Association</em> 93.444 (1998), pp. 1321-1339.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2670049" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Sadinle, M. and J. Reiter. <font color="#428bca">Sequential Identification of Nonignorable Missing Data Mechanisms</font>. In: <em>Statistica Sinica</em> 28.4 (2018), pp. 1741–1759.</cite></pref>
<div>
<a href="https://doi.org/10.5705/ss.202016.0328" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Seaman, S., J. Galati, D. Jackson, et al. <font color="#428bca">What Is Meant by “Missing at Random”?</font> In: <em>Statistical Science</em> 28.2 (2013), pp. 257–268.</cite></pref>
<div>
<a href="https://doi.org/10.2307/43288491" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a><a href="http://www.jstor.org/stable/43288491" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Shao, J. and J. Zhang. <font color="#428bca">A transformation approach in linear mixed-effects models with informative missing responses</font>. In: <em>Biometrika</em> 102.1 (2015), pp. 107-119.</cite></pref>
<div>
<a href="https://doi.org/10.1093/biomet/asu069" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Simon, G. and J. Simonoff. <font color="#428bca">Diagnostic plots for missing data in least squares regression</font>. In: <em>Journal of the American Statistical Association</em> 81.394 (1986), pp. 501-509.</cite></pref>
<div>
<a href="https://doi.org/10.1080/01621459.1986.10478296" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Stubbendick, A. and J. Ibrahim. <font color="#428bca">Maximum Likelihood Methods for Nonignorable Missing Responses and Covariates in Random Effects Models</font>. In: <em>Biometrics</em> 59.4 (2003), pp. 1140–1150.</cite></pref>
<div>
<a href="https://doi.org/10.1111/j.0006-341X.2003.00131.x" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Stubbendick, A. and J. Ibrahim. <font color="#428bca">Likelihood-based inference with nonignorable missing responses and covariates in models for discrete longitudinal data</font>. In: <em>Statistica Sinica</em> 16.4 (2006), pp. 1143–1167.</cite></pref>
<div>
<a href="https://www.jstor.org/stable/24307781" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
<li><pref><cite>Tchetgen Tchetgen, E., L. Wang and B. Sun. <font color="#428bca">Discrete choice models for nonmonotone nonignorable missing data: identification and inference</font>. In: <em>Statistica Sinica</em> 28.4 (2018), pp. 2069–2088.</cite></pref>
<div>
<a href="https://doi.org/10.5705/ss.202016.0325" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Templ, M., A. Alfons and P. Filzmoser. <font color="#428bca">Exploring Incomplete data using visualization techniques</font>. In: <em>Advances in Data Analysis and Classification</em> 6.1 (2012), pp. 29-47.</cite></pref>
<div>
<a href="https://doi.org/10.1007/s11634-011-0102-y" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Thijs, H., G. Molenberghs, B. Michiels, et al. <font color="#428bca">Strategies to fit pattern-mixture models</font>. In: <em>Biostatistics</em> 3.2 (2002), pp. 245-265.</cite></pref>
<div>
<a href="https://doi.org/10.1093/biostatistics/3.2.245" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Tierney, N., F. Harden, M. Harden, et al. <font color="#428bca">Using decision trees to understand structure in missing data</font>. In: <em>BMJ Open</em> 5.6 (2015), p. e007450.</cite></pref>
<div>
<a href="https://doi.org/10.1136/bmjopen-2014-007450" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Verbeke, G., G. Molenberghs, H. Thijs, et al. <font color="#428bca">Sensitivity analysis for nonrandom dropout: a local influence approach</font>. In: <em>Biometrics</em> 57.1 (2001), pp. 7-14.</cite></pref>
<div>
<a href="https://doi.org/10.1111/j.0006-341X.2001.00007.x" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Vansteelandt, S., A. Rotnitzky and J. Robins. <font color="#428bca">Estimation of regression models for the mean of repeated outcomes under nonignorable nonmonotone nonresponse</font>. In: <em>Biometrika</em> 94.4 (2007), pp. 841–860.</cite></pref>
<div>
<a href="https://doi.org/10.1093/biomet/asm070" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>White, I., J. Carpenter and N. Horton. <font color="#428bca">A mean score method for sensitivity analysis to departures from the missing at random assumption in randomised trials</font>. In: <em>Statistica Sinica</em> 28.4 (2018), pp. 1985–2003.</cite></pref>
<div>
<a href="https://doi.org/10.5705/ss.202016.0308" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Wu, M. and R. Carroll. <font color="#428bca">Estimation and comparison of changes in the presence of informative right censoring by modeling the censoring process</font>. In: <em>Biometrics</em> 44.1 (1988), pp. 175-188.</cite></pref>
<div>
<a href="https://doi.org/10.2307/2531905" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
<li><pref><cite>Zhou, Y., R. Little and J. Kalbfleisch. <font color="#428bca">Block-conditional missing at random models for missing data</font>. In: <em>Statistical Science</em> 25.4 (2010), pp. 517–532.</cite></pref>
<div>
<a href="https://doi.org/10.1214/10-STS344" target="blank" role="button" class="btn btn-outline-secondary btn-sm" >DOI</a>
</div></li>
</ul>
</div>
</div>
<!-- Conference papers -->
<!-- Reports, theses, etc. -->
<div class="container">
<button type="button" class="btn btn-sm" data-toggle="collapse" data-target="#mnar_misc">
Reports, theses, etc. (1)
</button>
<div id="mnar_misc" class="collapse">
<ul>
<li><pref><cite>Tierney, N. and D. Cook. <em><font color="#428bca">Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations</font></em>. Monash Econometrics and Business Statistics Working Papers 14/18. Monash University, Department of Econometrics and Business Statistics, 2018.</cite></pref>
<div>
<a href="https://ideas.repec.org/p/msh/ebswps/2018-14.html" target="_blank" role="button" class="btn btn-outline-secondary btn-sm" >URL</a>
</div></li>
</ul>
</div>
</div>
<p><br></p>
</div>
<div id="specific-application-fields" class="section level3">
<h3>Specific application fields</h3>
</div>
